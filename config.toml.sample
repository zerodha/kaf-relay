[app]
max_failovers = -1 # infinite
log_level = "debug"
metrics_server_addr = ":7081"

# In failover mode, if we breach the lag threshold in serverA compared to serverB we switch over to serverB immediately
lag_threshold = 100
# Frequency at which we need to poll for healthiness/lags
node_health_check_frequency = "500ms"

# Max request wait time to check if a node is down
max_request_duration = "100ms"


# Configuration for retry backoff settings.
# The retry backoff feature can be enabled or disabled.
# The minimum and maximum backoff durations can be specified.
[app.retry_backoff]
enable = true
min = "1s"
max = "10s"

# List of consumers for failover scenarios
[[consumers]]
name = "node1"
servers = ["node1:9092"]
session_timeout = "6s"
enable_auth = true
sasl_mechanism = "PLAIN"
username = "user-x"
password = "pass-x"
max_wait_time = "10ms"
# To not commit offsets, set this to 0.
offset_commit_interval = "100ms"
initial_offset = "start"
# consumer group id
group_id = "relay_group1"
# static memmbership to pin the member for the consumer group for respawn / reconnect and fence other members from connecting using the same id.
instance_id = "kaf_relay"

max_failovers = -1 # infinite

enable_tls = false
client_key_path = ""
client_cert_path = ""
ca_cert_path = ""

enable_log = false

[[consumers]]
name = "node2"
servers = ["node2:9092"]
session_timeout = "6s"
enable_auth = true
sasl_mechanism = "PLAIN"
username = "user-x"
password = "pass-x"
max_wait_time = "10ms"
# To not commit offsets, set this to 0.
offset_commit_interval = "100ms"
initial_offset = "start"
# consumer group id
group_id = "relay_group2"
# static memmbership to pin the member for the consumer group for respawn / reconnect and fence other members from connecting using the same id.
instance_id = "kaf_relay"

max_failovers = -1 # infinite

enable_tls = false
client_key_path = ""
client_cert_path = ""
ca_cert_path = ""

enable_log = false

# X => Y topic remapping where X is source topic and Y is destination topic
[topics]
topicA = "machineX_topicA"

# Destination kafka producer configuration
[producer]
name = "node3"
servers = ["node3:9092"]
enable_auth = true
sasl_mechanism = "PLAIN" # PLAIN/SCRAM-SHA-256/SCRAM-SHA-512
username = "user-y"
password = "pass-y"
max_retries = -1
enable_idempotency = true
commit_ack_type = "cluster"
flush_frequency = "20ms"
session_timeout = "6s"
flush_batch_size = 1000
batch_size = 1000
max_message_bytes = 10000000

enable_tls = false
client_key_path = ""
client_cert_path = ""
ca_cert_path = ""

enable_log = false

# Optional configuration to produce to a custom partition for a topic.
# Default behavior is to producer to same partition as the fetched consumer record.
[producer.partitioning]
topicA = [{'src' = 0, 'dest'=1}, {'src' = 1, 'dest'=2}]

# Custom go-plugin filter to load to filter messages when relaying
[filter.testfilter]
config = '''
{
    "address": ["127.0.0.1:6379"],
    "username": "",
    "password": "",
    "db": 10,
    "max_active": 50,
    "max_idle": 20,
    "dial_timeout": 3000,
    "read_timeout": 3000,
    "write_timeout": 3000,
    "idle_timeout": 30000
}
'''